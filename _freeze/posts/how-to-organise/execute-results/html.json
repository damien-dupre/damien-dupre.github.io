{
  "hash": "cf8bf5fcc79d5aa2eadd30350e5b91fd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"How to Organise a Wedding Using R: Google Search API, Google Drive, Web Scraping, and Automated Emails\"\n\nexecute: \n  eval: false\n---\n\n::: {.callout-note}\nThis post first appeared on my {blogdown} site, now archived. After a recent request from someone looking to use the same approach, I decided to bring it back on my current Quarto site, unchanged from the original.\n\nSee @sec-updates for my latest notes.\n:::\n\nPlanning a wedding is a challenge. For R users, we have one advantage: automation. One of the trickiest parts is finding a venue. There are plenty, but many will already be booked for your date. Here is how I created a list of potential venues with the Google Search API, stored it on Google Drive, scraped emails, and sent messages, all with R.\n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# store passwords\nlibrary(config)\n# data wrangling\nlibrary(plyr)\nlibrary(tidyverse)\nlibrary(purrr)\nlibrary(glue)\n# google APIs\nlibrary(googleway)\nlibrary(googledrive)\n# webscraping\nlibrary(rvest)\n# send emails\nlibrary(mailR)\nlibrary(XML)\nlibrary(RCurl)\n# html widgets\nlibrary(DT)\nlibrary(leaflet)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngmail_wedding <- config::get(\"gmail_wedding\")\ngoogle_key <- config::get(\"google_cloud\")\n```\n:::\n\n\n## Creating a venue list with the Google Places API\n\nSince R offers a package for almost everything, I used {googleway} to pull venue data from Google Places. [This API includes several services](https://console.cloud.google.com/apis/) like Directions, Geolocation and Places. To use it, you must register a card on Google Cloud to get an API key. Used moderately, this is free. [I found this Stack Overflow answer helpful when learning googleway](https://stackoverflow.com/questions/28026897/google-place-with-r).\n\n### Targeted cities\n\nI wanted my wedding in the Auvergne-Rhone-Alpes region of France. A single search term like “Auvergne-Rhone-Alpes” might not catch all options, so I built a loop that searches by city. My list of cities comes from their department codes (e.g. the department codes 01, 07, 26, 38, 69, 73 and 74 correspond to Ain, Ardèche, Drôme, Isère, Rhône, Savoie and Haute-Savoie in France).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndept_target <- c(01, 07, 26, 38, 69, 73, 74)\n#\nlist_city <- read.csv(\n  file = url(\"https://sql.sh/ressources/sql-villes-france/villes_france.csv\"),\n  header = FALSE\n) %>%\n  dplyr::select(dept = V2, city = V5, pop2010 = V15) %>%\n  dplyr::mutate(city = as.character(city)) %>%\n  dplyr::filter(dept %in% dept_target) %>% # filter by target departments\n  dplyr::filter(pop2010 > 5000) %>% # filter by city population size\n  magrittr::use_series(city)\n```\n:::\n\n\n### Querying Google Places\n\nOnce the cities are ready, I run a loop querying Google Places for each one. If a next page token is found, the script fetches results from subsequent pages until all results are retrieved.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_places_final <- NULL\nfor (city in list_city) {\n  # print(city)\n\n  df_places <- googleway::google_places(\n    search_string = paste(\"mariage\", city, \"france\"),\n    key = google_key$key\n  ) # replace by your Google API key\n\n  if (length(df_places$results) == 0) next\n\n  df_places_results <- df_places$results\n  geometry <- df_places_results$geometry$location\n  df_places_results <- df_places_results[, c(\"name\", \"formatted_address\", \"place_id\", \"types\")]\n  df_places_results <- cbind(df_places_results, geometry)\n\n  while (!is.null(df_places$next_page_token)) {\n    df_places <- googleway::google_places(\n      search_string = paste(\"mariage\", city, \"france\"),\n      page_token = df_places$next_page_token,\n      key = google_key$key\n    )\n\n    df_places_next <- df_places$results\n\n    if (length(df_places_next) > 0) {\n      geometry <- df_places_next$geometry$location\n      df_places_next <- df_places_next[, c(\"name\", \"formatted_address\", \"place_id\", \"types\")]\n      df_places_next <- cbind(df_places_next, geometry)\n      df_places_results <- rbind(df_places_results, df_places_next)\n    }\n    Sys.sleep(2) # time to not overload  the google API\n  }\n  df_places_final <- rbind(df_places_final, df_places_results)\n}\n```\n:::\n\n\nThe raw results include caterers, photographers and shops. I filtered them to keep only venues such as castles, mansions and estates. Duplicates are also removed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_places_filtered <- df_places_final %>%\n  dplyr::filter(grepl(\"castle|chateau|domaine|manoir|ferme\", name, ignore.case = TRUE)) %>%\n  dplyr::distinct(place_id, .keep_all = TRUE)\n```\n:::\n\n\nWith {leaflet}, I visualised the locations on a map.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleaflet() %>%\n  addTiles() %>% # Add default OpenStreetMap map tiles\n  addMarkers(lng = df_places_filtered$lng, lat = df_places_filtered$lat, popup = df_places_filtered$name)\n```\n:::\n\n\n### Getting venue websites\n\nThe first API call does not return website URLs, but `google_place_details()` does. Using {purrr}, I applied a small function to fetch them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_website <- function(place_id) {\n  # print(place_id)\n  place_id <- as.character(place_id)\n  dat <- googleway::google_place_details(place_id = place_id, key = google_key$key)\n  res <- ifelse(is.null(dat$result$website), \"no_website\", dat$result$website)\n  return(res)\n}\n\nwebsite_list <- df_places_filtered$place_id %>%\n  purrr::map(get_website) %>%\n  unlist()\ndf_places_filtered$website <- website_list\n```\n:::\n\n\nI removed venues without websites and cleaned up the remaining URLs for later use in web scraping.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_places_filtered <- df_places_filtered %>%\n  dplyr::filter(website != \"no_website\") %>%\n  dplyr::mutate(website = gsub(\"\\\\,.*\", \"\", website)) %>%\n  dplyr::mutate(website = gsub(\"com/fr\", \"com\", website)) %>%\n  dplyr::mutate(website_contact = paste0(website, \"contact\"))\n```\n:::\n\n\nThe list of venues is now \"clean\" we can start the web scraping to obtain venues' emails.\n\n## Scraping websites for emails\n\nGoogle does not provide emails, so I scraped the websites using {rvest}. Most venues list emails on their home or contact page. A simple function handles this, with `tryCatch()` to skip broken URLs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_email <- function(website) {\n  # print(website)\n  url_test <- tryCatch(xml2::read_html(website), error = function(e) print(\"url_error\"))\n  if (url_test == \"url_error\") {\n    return(NA)\n  } else {\n    text_web <- xml2::read_html(website) %>%\n      rvest::html_text()\n    email_text <- unlist(regmatches(text_web, gregexpr(\"([_a-z0-9-]+(\\\\.[_a-z0-9-]+)*@[a-z0-9-]+(\\\\.[a-z0-9-]+)*(\\\\.[a-z]{2,4}))\", text_web)))\n    email_text <- gsub(\"\\n\", \"\", email_text)\n    email_text <- gsub(\" \", \"\", email_text)\n    return(email_text[1])\n  }\n}\n# web scraping home page\nemail_list <- df_places_filtered$website %>%\n  purrr::map(extract_email) %>%\n  unlist()\ndf_places_filtered$email <- email_list\n# web scraping contact page\nemail_list <- df_places_filtered$website_contact %>%\n  purrr::map(extract_email) %>%\n  unlist()\ndf_places_filtered$email_contact <- email_list\n# merge email and email_contact\ndf_places_filtered <- df_places_filtered %>%\n  dplyr::mutate(email = ifelse(is.na(email), email_contact, email)) %>%\n  dplyr::filter(!is.na(email)) %>%\n  dplyr::select(-email_contact, -types)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_places_filtered %>%\n  dplyr::select(name, website) %>%\n  DT::datatable(options = list(pageLength = 5))\n```\n:::\n\n\nWe now have a list of venues to contact.\n\n## Google Drive and automated emails\n\nIt helps to create a separate email account just for wedding planning. Google makes this easy and also offers Google Drive for storing documents. With the {googledrive} package, sharing and updating files with your partner is straightforward (see https://googledrive.tidyverse.org/index.html for some information about {googledrive}).\n\n### Uploading the list to Google Drive\n\nFirst, save the data frame locally, then upload.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# first save the list of venues local\nwrite.csv(df_places_filtered, \"list_venues.csv\", row.names = FALSE)\n# upload to google drive\ndrive_upload(media = \"list_venues.csv\", name = \"list_venues\", type = \"spreadsheet\")\n```\n:::\n\n\n### Downloading from Google Drive\n\nYou can then download and reload the file when needed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# select file id from google drive\nlist_venues_id <- drive_find() %>%\n  dplyr::filter(name == \"list_venues\") %>%\n  magrittr::use_series(id)\n# download list of venues locally\ndrive_download(as_id(list_venues_id), overwrite = TRUE, type = \"csv\")\n# read local list of venues file\nlist_venues <- read.csv(\"list_venues.csv\", row.names = NULL) %>%\n  dplyr::mutate_if(is.factor, as.character)\n```\n:::\n\n\n### Sending emails\n\nWith the list ready, I sent emails in a simple loop. The script extracts each venue name and email and sends a standard message asking about availability. [Make sure to allow less secure apps in Gmail settings](https://support.google.com/accounts/answer/6010255?hl=en).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_to_send <- list_venues\n#\n# Email to send\nemail_text <- \"<p>Dear owner/manager of '{name}', <br><br>We are contacting you because we would like to organise our wedding <b>Sunday 9 of June 2019</b> and your plac would be amazing for it.<br><br>That's why we would like to know if your venue '{name}' is available <b>Sunday 9 of June 2019</b>?</b><br><br>Best regards,<br><br>YOUR NAMES</p>\"\n#\nfor (i in 1:nrow(email_to_send)) {\n  df <- email_to_send[i, ]\n  name <- as.character(df$name)\n  ################################\n  send.mail(\n    from = gmail_wedding$email,\n    to = as.character(df$email),\n    subject = \"Availability for a wedding on the 09/06/2019\",\n    body = glue::glue(email_text),\n    smtp = list(\n      host.name = \"smtp.gmail.com\", port = 465,\n      user.name = gmail_wedding$email,\n      passwd = gmail_wedding$passwd, ssl = TRUE\n    ),\n    authenticate = TRUE,\n    send = TRUE,\n    html = TRUE\n  )\n}\n```\n:::\n\n\nAfter sending, I updated the contact date in the data to avoid duplicates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemail_to_send <- email_to_send %>%\n  dplyr::mutate(date_contact = as.character(as.Date(Sys.Date()))) %>%\n  dplyr::mutate(type_contact = \"automatic email\")\n# Checks in case of different batch of email sending\nid <- match(list_venues$name, email_to_send$name, nomatch = 0L)\nlist_venues$date_contact[id != 0] <- email_to_send$date_contact[id]\nlist_venues$type_contact[id != 0] <- email_to_send$type_contact[id]\n# Write data on local and Upload data from local to google drive\nwrite.csv(list_venues, \"ist_venues.csv\", row.names = FALSE)\ndrive_update(file = \"list_venues\", media = \"list_venues.csv\")\n```\n:::\n\n\nI hope these scripts help you find the perfect venue. Best of luck with your planning.\n\n## Updates and Comments {#sec-updates}\n\nSince I wrote this code in 2018, things have changed. I would rely less on for loops and use {purrr} map or walk functions instead.\n\nTo send batch emails with Gmail, I now use {blastula} instead of {mailR}.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}