{
  "hash": "e338c945bcda2f623a9f1a091f662cf1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Time series clustering with Dynamic Time Warping (Part 2)\"\n\nexecute: \n  eval: true\n  warning: false\n---\n\nLike any good movie, my previous post, \"Time Series Clustering with Dynamic Time Warping,\" deserves a sequel. In this Part 2, I'll examine athletes' training plans for a marathon. Because marathons are so demanding, most runners follow a specific training plan to prepare. You can find many different plans on the web, [like this one from Run Ireland](https://www.runireland.com/wp-content/uploads/2018/01/Training_for_marathon.pdf).\n\nIn this post, I'll attempt to cluster several simulated training plans. To do this, I will use Dynamic Time Warping combined with feature extraction techniques like seasonality decomposition, state-space models, and power spectrum analysis.\n\n### List of packages needed\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# data wrangling\nlibrary(dplyr) # data wrangling\nlibrary(tidyr) # datawrangling\n# analysis\nlibrary(dtwclust) # dynamic time warpping\nlibrary(depmixS4) # Hidden Markov Model\nlibrary(WaveletComp) # Wavelet Analysis\n# graphics\nlibrary(ggplot2) # grammar of graphics\nlibrary(ggdendro) # grammar of dendrograms\nlibrary(gtable) # plot organisation\nlibrary(grid) # plot organisation\nlibrary(gridExtra) # plot organisation\n```\n:::\n\n\n### Data simulation\n\nFor this analysis, I'll create a dataset of 20 simulated athlete training plans. Ten of these will be random, while the other ten will follow a repeating pattern, but with non-synchronized dates and intensities. The main variable is the distance run each day over the 25 weeks (175 days) leading up to the marathon.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndate_marathon <- as.Date(\"2015-10-26\")\n#\ndf <- NULL\n# random training plan with runs from 5 to 40km with a high proability of non run days (between 25% and 75% depending on athletes)\nfor (i in 1:10) {\n  random_proba <- runif(8)\n  random_proba <- random_proba / sum(random_proba)\n  value <- base::sample(\n    x = seq(from = 0, to = 40, by = 5),\n    size = 175,\n    replace = TRUE,\n    prob = c(runif(1, 0.25, 0.75), random_proba)\n  )\n  athlete <- paste0(\"athlete_rand_\", i)\n  new_df <- data.frame(athlete = athlete, value = value, rundate = seq.Date(date_marathon - 175, date_marathon - 1, by = \"day\"))\n  df <- rbind(df, new_df)\n}\n# training plan with a reapeated pattern with can change according the weeks and with a different intensity according athletes\nfor (i in 11:20) {\n  value <- rep_len(\n    x = c(rep(x = 0, sample(1:3, 1)), 10, 0, 15, 20, 30) * runif(1, 0.5, 1.5),\n    length.out = 175\n  )\n  athlete <- paste0(\"athlete_plan_\", i)\n  new_df <- data.frame(athlete = athlete, value = value, rundate = seq.Date(date_marathon - 175, date_marathon - 1, by = \"day\"))\n  df <- rbind(df, new_df)\n}\n```\n:::\n\n\nOnce the data is generated, a key step is to convert the data frame into a list of time series. This structure is important because it opens up the possibility of implementing a multivariate DTW analysis in the future (perhaps in a Part 3 ðŸ˜‰).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan_list <- df %>%\n  tidyr::spread(athlete, value) %>%\n  dplyr::select(-rundate) %>%\n  purrr::map(~ (.))\n```\n:::\n\n\n## DTW cluster on raw data\n\nAfter preparing the data list, let's run a simple DTW clustering on the raw data to see if we can identify our two groups.\n\n### DTW model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNclust <- 2\ndtw_model <- dtwclust::tsclust(\n  series = plan_list,\n  type = \"h\",\n  k = Nclust,\n  distance = \"dtw_basic\",\n  control = hierarchical_control(method = \"complete\"),\n  preproc = NULL,\n  # args = tsclust_args(dist = list(window.size = 5L)),\n  trace = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCalculating distance matrix...\nPerforming hierarchical clustering...\nExtracting centroids...\n\n\tElapsed time is 0.041 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\n#\ndtw_data <- ggdendro::dendro_data(dtw_model, type = \"rectangle\")\n#\nlabels_order <- dtw_data$labels$label\n#\ndtw_result <- data.frame(\n  label = names(plan_list),\n  cluster = factor(stats::cutree(dtw_model, k = Nclust))\n)\n#\ndtw_data[[\"labels\"]] <- merge(dtw_data[[\"labels\"]], dtw_result, by = \"label\")\ndtw_result <- dplyr::full_join(dtw_result, dtw_data$labels, by = c(\"label\", \"cluster\")) %>%\n  dplyr::arrange(x)\n```\n:::\n\n\n### DTW plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_box <- aggregate(x ~ cluster, ggdendro::label(dtw_data), range)\ncluster_box <- data.frame(cluster_box$cluster, cluster_box$x)\ncluster_threshold <- mean(dtw_model$height[length(dtw_model$height) - ((Nclust - 2):(Nclust - 1))])\n#\nnumColors <- length(levels(dtw_result$cluster)) # How many colors you need\ngetColors <- scales::hue_pal() # Create a function that takes a number and returns a qualitative palette of that length (from the scales package)\nmyPalette <- getColors(numColors)\nnames(myPalette) <- levels(dtw_result$cluster) # Give every color an appropriate name\n\np1 <- ggplot() +\n  geom_rect(data = cluster_box, aes(xmin = X1 - .3, xmax = X2 + .3, ymin = 0, ymax = cluster_threshold, color = cluster_box.cluster), fill = NA) +\n  geom_segment(data = ggdendro::segment(dtw_data), aes(x = x, y = y, xend = xend, yend = yend)) +\n  coord_flip() +\n  scale_y_continuous(\"Distance\") +\n  scale_x_continuous(\"\", breaks = 1:20, labels = labels_order) +\n  guides(color = FALSE, fill = FALSE) +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(), # remove grids\n    panel.background = element_blank(),\n    axis.text.y = element_text(colour = myPalette[dtw_result$cluster], hjust = 0.5),\n    axis.ticks.y = element_blank()\n  )\n#\np2 <- as.data.frame(matrix(unlist(plan_list),\n  nrow = length(unlist(plan_list[1])),\n  dimnames = list(c(), names(plan_list))\n)) %>%\n  dplyr::mutate(rundatelocal = seq.Date(date_marathon - 175, date_marathon - 1, by = \"day\")) %>%\n  tidyr::gather(key = label, value = value, -rundatelocal) %>%\n  dplyr::mutate(label = as.factor(label)) %>%\n  dplyr::full_join(., dtw_result, by = \"label\") %>%\n  mutate(label = factor(label, levels = rev(as.character(labels_order)))) %>%\n  ggplot(aes(x = rundatelocal, y = value, colour = as.factor(cluster))) +\n  geom_line() +\n  geom_area(aes(fill = as.factor(cluster))) +\n  coord_cartesian(ylim = c(0, 50)) +\n  scale_y_continuous(name = \"Total distance per day [km]\", breaks = seq(0, 50, by = 50)) +\n  scale_x_date(name = \"Run Date\", date_breaks = \"4 week\", date_labels = \"%b %d\") +\n  facet_wrap(~label, ncol = 1, strip.position = \"left\") +\n  guides(color = FALSE, fill = FALSE) +\n  theme_bw() +\n  theme(strip.background = element_blank(), strip.text = element_blank())\n#\nplt_list <- list(p2, p1)\nplt_layout <- rbind(\n  c(NA, 2),\n  c(1, 2),\n  c(NA, 2)\n)\n#\ngrid.arrange(grobs = plt_list, layout_matrix = plt_layout, heights = c(0.04, 1, 0.05))\n```\n\n::: {.cell-output-display}\n![](timeseries-clustering-part2_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nThanks to some solutions on Stack Overflow, I think the plot looks good graphically (I'm still working on the label overlap). The results aren't bad, but some random plans were grouped with the structured plans. Of course, randomness can sometimes produce patterns by chance. It's also interesting that a higher number of clusters might be needed to achieve a cleaner separation.\n\n### Centroids\n\nWe can also examine the centroids to see which plans are most representative of each cluster. This isn't very useful with only two clusters, but it can be a key tool for distinguishing between many different training plans.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndtw_model_centroids <- data.frame(dtw_model@centroids, rundatelocal = seq.Date(date_marathon - 175, date_marathon - 1, by = \"day\")) %>%\n  tidyr::gather(label, totaldistancekm, starts_with(\"athlete\")) %>%\n  dplyr::left_join(., dtw_result, by = \"label\") %>%\n  dplyr::mutate(label = factor(label, levels = rev(labels_order)))\n#\ndtw_model_centroids %>%\n  ggplot(aes(rundatelocal, totaldistancekm, color = cluster, fill = cluster)) +\n  geom_line() +\n  geom_area() +\n  facet_wrap(~ label + cluster, ncol = 1, strip.position = \"right\", labeller = labeller(.rows = label_both)) +\n  scale_y_continuous(name = \"Total distance per day [km]\") +\n  scale_x_date(name = \"Run Date\", date_breaks = \"4 week\", date_labels = \"%b %d\") +\n  guides(color = FALSE, fill = FALSE) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](timeseries-clustering-part2_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nThe main problem with raw data is noise. When trying to extract recurring patterns, random noise can sometimes create meaningless shapes that distort the cluster structure. Since we're interested in classifying recurring patterns, removing this noise is a good idea. Signal processing offers many techniques for this, such as seasonality decomposition, Hidden Markov Models, and power spectrum analysis.\n\n## DTW cluster with seasonality decomposition\n\nWhen it comes to time series analysis in R, certain packages and functions are indispensable. You likely can't get far without `zoo::zoo()`, `xts::xts()`, or `tibbletime::as_tbl_time()`. However, the base {stats} package contains one of the most useful functions: `stl()`. This function performs a Seasonal Decomposition of Time Series by Loess, which is a powerful way to separate a time series into its trend, seasonal, and noise components. Here, we'll use `stl()` to extract the weekly seasonality from each training plan and then cluster the results with DTW.\n\nFirst, let's apply the `stl()` decomposition to every time series in our list.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_seasonality <- function(x, robust) {\n  x_ts <- ts(as.numeric(unlist(x)), frequency = 7)\n  stl_test <- stl(x_ts, s.window = 7, robust)\n  return(stl_test$time.series[, 1])\n}\n#\nplan_seasonality <- plan_list %>%\n  purrr::map(~ extract_seasonality(., robust = TRUE))\n```\n:::\n\n\nNext, we'll process the model and plot the results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNclust <- 2\ndtw_model <- dtwclust::tsclust(\n  series = plan_seasonality,\n  type = \"h\",\n  k = Nclust,\n  distance = \"dtw_basic\",\n  control = hierarchical_control(method = \"complete\"),\n  preproc = NULL,\n  # args = tsclust_args(dist = list(window.size = 5L)),\n  trace = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCalculating distance matrix...\nPerforming hierarchical clustering...\nExtracting centroids...\n\n\tElapsed time is 0.051 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\n#\ndtw_data <- ggdendro::dendro_data(dtw_model, type = \"rectangle\")\n#\nlabels_order <- dtw_data$labels$label\n#\ndtw_result <- data.frame(\n  label = names(plan_seasonality),\n  cluster = factor(stats::cutree(dtw_model, k = Nclust))\n)\n#\ndtw_data[[\"labels\"]] <- merge(dtw_data[[\"labels\"]], dtw_result, by = \"label\")\ndtw_result <- dplyr::full_join(dtw_result, dtw_data$labels, by = c(\"label\", \"cluster\")) %>%\n  dplyr::arrange(x)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_box <- aggregate(x ~ cluster, ggdendro::label(dtw_data), range)\ncluster_box <- data.frame(cluster_box$cluster, cluster_box$x)\ncluster_threshold <- mean(dtw_model$height[length(dtw_model$height) - ((Nclust - 2):(Nclust - 1))])\n#\nnumColors <- length(levels(dtw_result$cluster)) # How many colors you need\ngetColors <- scales::hue_pal() # Create a function that takes a number and returns a qualitative palette of that length (from the scales package)\nmyPalette <- getColors(numColors)\nnames(myPalette) <- levels(dtw_result$cluster) # Give every color an appropriate name\n\np1 <- ggplot() +\n  geom_rect(data = cluster_box, aes(xmin = X1 - .3, xmax = X2 + .3, ymin = 0, ymax = cluster_threshold, color = cluster_box.cluster), fill = NA) +\n  geom_segment(data = ggdendro::segment(dtw_data), aes(x = x, y = y, xend = xend, yend = yend)) +\n  coord_flip() +\n  scale_y_continuous(\"Distance\") +\n  scale_x_continuous(\"\", breaks = 1:20, labels = labels_order) +\n  guides(color = FALSE, fill = FALSE) +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(), # remove grids\n    panel.background = element_blank(),\n    axis.text.y = element_text(colour = myPalette[dtw_result$cluster], hjust = 0.5),\n    axis.ticks.y = element_blank()\n  )\n#\np2 <- as.data.frame(matrix(unlist(plan_seasonality),\n  nrow = length(unlist(plan_seasonality[1])),\n  dimnames = list(c(), names(plan_seasonality))\n)) %>%\n  dplyr::mutate(rundatelocal = seq.Date(date_marathon - 175, date_marathon - 1, by = \"day\")) %>%\n  tidyr::gather(key = label, value = value, -rundatelocal) %>%\n  dplyr::mutate(label = as.factor(label)) %>%\n  dplyr::full_join(., dtw_result, by = \"label\") %>%\n  mutate(label = factor(label, levels = rev(as.character(labels_order)))) %>%\n  ggplot(aes(x = rundatelocal, y = value, colour = as.factor(cluster))) +\n  geom_line() +\n  geom_area(aes(fill = as.factor(cluster))) +\n  coord_cartesian(ylim = c(-25, 25)) +\n  scale_y_continuous(name = \"Seasonal distance per day [km]\", breaks = seq(-25, 25, by = 50)) +\n  scale_x_date(name = \"Run Date\", date_breaks = \"4 week\", date_labels = \"%b %d\") +\n  facet_wrap(~label, ncol = 1, strip.position = \"left\") +\n  guides(color = FALSE, fill = FALSE) +\n  theme_bw() +\n  theme(strip.background = element_blank(), strip.text = element_blank())\n#\nplt_list <- list(p2, p1)\nplt_layout <- rbind(\n  c(NA, 2),\n  c(1, 2),\n  c(NA, 2)\n)\n#\ngrid.arrange(grobs = plt_list, layout_matrix = plt_layout, heights = c(0.04, 1, 0.05))\n```\n\n::: {.cell-output-display}\n![](timeseries-clustering-part2_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nWell, I think that's an epic fail. Let's explore why. Several reasons could explain why we have one cluster with only 3 time series and another with the remaining 17:\n\n1. I'm only using two clusters. In reality (and with real randomness), many more patterns are possible. Increasing the number of clusters could make the clustering more effective, especially if combined with an evaluation of the optimal cluster count.\n2. By removing the noise from the random plans, I inadvertently made them less random, revealing underlying repetitive patterns. This is exactly what I want to do with real data in my research, but here, it just made a mess.\n\nSo, let's try another method!\n\n## DTW cluster with Hidden Markov Model\n\nI'm not an expert in Hidden Markov Models (HMMs), and after looking at the book [Hidden Markov Models for Time Series: An Introduction Using R](https://www.crcpress.com/p/book/9781482253832) by Zucchini, MacDonald, and Langrock, I can confirm it's a complex topic. In a nutshell, HMMs cluster values based on their probability of belonging to a hidden \"state.\"\n\nIn our case, let's assume we have three possible states for each day: \"no run,\" \"medium run,\" and \"long run.\" Using an HMM, we can create new time series based on these states instead of distances. This is a qualitative transformation that requires almost no prior assumptions about the state boundaries.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan_HMM <- as.data.frame(matrix(unlist(plan_list),\n  nrow = length(unlist(plan_list[1])),\n  dimnames = list(c(), names(plan_list))\n)) %>%\n  dplyr::mutate(rundatelocal = seq.Date(date_marathon - 175, date_marathon - 1, by = \"day\")) %>%\n  tidyr::gather(key = label, value = value, -rundatelocal) %>%\n  dplyr::mutate(label = as.factor(label)) %>%\n  dplyr::mutate(value = as.integer(value))\n#\nmod <- depmixS4::depmix(value ~ label, family = poisson(link = \"log\"), nstates = 3, data = plan_HMM)\n#\nfm <- depmixS4::fit(mod, verbose = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nconverged at iteration 55 with logLik: -10442.8 \n```\n\n\n:::\n\n```{.r .cell-code}\n#\nprobs <- depmixS4::posterior(fm)\n#\nplan_HMM <- cbind(plan_HMM, probs) %>%\n  dplyr::select(rundatelocal, label, state) %>%\n  tidyr::spread(label, state) %>%\n  dplyr::select(-rundatelocal) %>%\n  purrr::map(~ (.))\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNclust <- 2\ndtw_model <- dtwclust::tsclust(\n  series = plan_HMM,\n  type = \"h\",\n  k = Nclust,\n  distance = \"dtw_basic\",\n  control = hierarchical_control(method = \"complete\"),\n  preproc = NULL,\n  # args = tsclust_args(dist = list(window.size = 5L)),\n  trace = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCalculating distance matrix...\nPerforming hierarchical clustering...\nExtracting centroids...\n\n\tElapsed time is 0.025 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\n#\ndtw_data <- ggdendro::dendro_data(dtw_model, type = \"rectangle\")\n#\nlabels_order <- dtw_data$labels$label\n#\ndtw_result <- data.frame(\n  label = names(plan_HMM),\n  cluster = factor(stats::cutree(dtw_model, k = Nclust))\n)\n#\ndtw_data[[\"labels\"]] <- merge(dtw_data[[\"labels\"]], dtw_result, by = \"label\")\ndtw_result <- dplyr::full_join(dtw_result, dtw_data$labels, by = c(\"label\", \"cluster\")) %>%\n  dplyr::arrange(x)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_box <- aggregate(x ~ cluster, ggdendro::label(dtw_data), range)\ncluster_box <- data.frame(cluster_box$cluster, cluster_box$x)\ncluster_threshold <- mean(dtw_model$height[length(dtw_model$height) - ((Nclust - 2):(Nclust - 1))])\n#\nnumColors <- length(levels(dtw_result$cluster)) # How many colors you need\ngetColors <- scales::hue_pal() # Create a function that takes a number and returns a qualitative palette of that length (from the scales package)\nmyPalette <- getColors(numColors)\nnames(myPalette) <- levels(dtw_result$cluster) # Give every color an appropriate name\n\np1 <- ggplot() +\n  geom_rect(data = cluster_box, aes(xmin = X1 - .3, xmax = X2 + .3, ymin = 0, ymax = cluster_threshold, color = cluster_box.cluster), fill = NA) +\n  geom_segment(data = ggdendro::segment(dtw_data), aes(x = x, y = y, xend = xend, yend = yend)) +\n  coord_flip() +\n  scale_y_continuous(\"Distance\") +\n  scale_x_continuous(\"\", breaks = 1:20, labels = labels_order) +\n  guides(color = FALSE, fill = FALSE) +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(), # remove grids\n    panel.background = element_blank(),\n    axis.text.y = element_text(colour = myPalette[dtw_result$cluster], hjust = 0.5),\n    axis.ticks.y = element_blank()\n  )\n#\np2 <- as.data.frame(matrix(unlist(plan_HMM),\n  nrow = length(unlist(plan_HMM[1])),\n  dimnames = list(c(), names(plan_HMM))\n)) %>%\n  dplyr::mutate(rundatelocal = seq.Date(date_marathon - 175, date_marathon - 1, by = \"day\")) %>%\n  tidyr::gather(key = label, value = value, -rundatelocal) %>%\n  dplyr::mutate(label = as.factor(label)) %>%\n  dplyr::full_join(., dtw_result, by = \"label\") %>%\n  mutate(label = factor(label, levels = rev(as.character(labels_order)))) %>%\n  ggplot(aes(x = rundatelocal, y = value, colour = as.factor(cluster))) +\n  geom_line() +\n  geom_area(aes(fill = as.factor(cluster))) +\n  coord_cartesian(ylim = c(0, 4)) +\n  scale_y_continuous(name = \"States per day [km]\", breaks = seq(0, 4, by = 4)) +\n  scale_x_date(name = \"Run Date\", date_breaks = \"4 week\", date_labels = \"%b %d\") +\n  facet_wrap(~label, ncol = 1, strip.position = \"left\") +\n  guides(color = FALSE, fill = FALSE) +\n  theme_bw() +\n  theme(strip.background = element_blank(), strip.text = element_blank())\n#\nplt_list <- list(p2, p1)\nplt_layout <- rbind(\n  c(NA, 2),\n  c(1, 2),\n  c(NA, 2)\n)\n#\ngrid.arrange(grobs = plt_list, layout_matrix = plt_layout, heights = c(0.04, 1, 0.05))\n```\n\n::: {.cell-output-display}\n![](timeseries-clustering-part2_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nGood news this time: the clusters are almost equally distributed. Bad news: the random and structured plans are mixed together. However, the HMM creates surprisingly clean patterns that could easily be clustered with a higher number of clusters. The main drawback is the low distance between each time series, which could complicate the clustering.\n\n## DTW cluster by power spectral density\n\nLast but not least, perhaps the best approach for evaluating seasonality in training plans is power spectrum analysis. By identifying the underlying frequencies in each time series, we can cluster them according to their dominant patterns. The excellent {WaveletComp} package is perfect for this, as it analyses the frequency structure of time series using the Morlet wavelet.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNclust <- 2\ndtw_model <- dtwclust::tsclust(\n  series = plan_poweravge,\n  type = \"h\",\n  k = Nclust,\n  distance = \"dtw_basic\",\n  control = hierarchical_control(method = \"complete\"),\n  preproc = NULL,\n  # args = tsclust_args(dist = list(window.size = 5L)),\n  trace = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCalculating distance matrix...\nPerforming hierarchical clustering...\nExtracting centroids...\n\n\tElapsed time is 0.009 seconds.\n```\n\n\n:::\n\n```{.r .cell-code}\n#\n\ndtw_data <- ggdendro::dendro_data(dtw_model, type = \"rectangle\")\n#\nlabels_order <- dtw_data$labels$label\n#\ndtw_result <- data.frame(\n  label = names(plan_poweravge),\n  cluster = factor(stats::cutree(dtw_model, k = Nclust))\n)\n#\ndtw_data[[\"labels\"]] <- merge(dtw_data[[\"labels\"]], dtw_result, by = \"label\")\ndtw_result <- dplyr::full_join(dtw_result, dtw_data$labels, by = c(\"label\", \"cluster\")) %>%\n  dplyr::arrange(x)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncluster_box <- aggregate(x ~ cluster, ggdendro::label(dtw_data), range)\ncluster_box <- data.frame(cluster_box$cluster, cluster_box$x)\ncluster_threshold <- mean(dtw_model$height[length(dtw_model$height) - ((Nclust - 2):(Nclust - 1))])\n#\nnumColors <- length(levels(dtw_result$cluster)) # How many colors you need\ngetColors <- scales::hue_pal() # Create a function that takes a number and returns a qualitative palette of that length (from the scales package)\nmyPalette <- getColors(numColors)\nnames(myPalette) <- levels(dtw_result$cluster) # Give every color an appropriate name\n\np1 <- ggplot() +\n  geom_rect(data = cluster_box, aes(xmin = X1 - .3, xmax = X2 + .3, ymin = 0, ymax = cluster_threshold, color = cluster_box.cluster), fill = NA) +\n  geom_segment(data = ggdendro::segment(dtw_data), aes(x = x, y = y, xend = xend, yend = yend)) +\n  coord_flip() +\n  scale_y_continuous(\"Distance\") +\n  scale_x_continuous(\"\", breaks = 1:20, labels = labels_order) +\n  guides(color = FALSE, fill = FALSE) +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(), # remove grids\n    panel.background = element_blank(),\n    axis.text.y = element_text(colour = myPalette[dtw_result$cluster], hjust = 0.5),\n    axis.ticks.y = element_blank()\n  )\n#\np2 <- as.data.frame(matrix(unlist(plan_poweravge),\n  nrow = length(unlist(plan_poweravge[1])),\n  dimnames = list(c(), names(plan_poweravge))\n)) %>%\n  dplyr::mutate(rundatelocal = 1:n()) %>%\n  tidyr::gather(key = label, value = value, -rundatelocal) %>%\n  dplyr::mutate(label = as.factor(label)) %>%\n  dplyr::full_join(., dtw_result, by = \"label\") %>%\n  mutate(label = factor(label, levels = rev(as.character(labels_order)))) %>%\n  ggplot(aes(x = rundatelocal, y = value, colour = as.factor(cluster))) +\n  geom_line() +\n  geom_area(aes(fill = as.factor(cluster))) +\n  coord_cartesian(ylim = c(0, 1)) +\n  scale_y_continuous(name = \"Average power density\", breaks = seq(0, 1, by = 1)) +\n  scale_x_continuous(name = \"Period (days)\") +\n  facet_wrap(~label, ncol = 1, strip.position = \"left\") +\n  guides(color = FALSE, fill = FALSE) +\n  theme_bw() +\n  theme(strip.background = element_blank(), strip.text = element_blank())\n#\nplt_list <- list(p2, p1)\nplt_layout <- rbind(\n  c(NA, 2),\n  c(1, 2),\n  c(NA, 2)\n)\n#\ngrid.arrange(grobs = plt_list, layout_matrix = plt_layout, heights = c(0.04, 1, 0.05))\n```\n\n::: {.cell-output-display}\n![](timeseries-clustering-part2_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nThis frequency decomposition looks amazing! However, be careful: the power frequencies are averaged. As stated in the [package's guided tour](http://www.hs-stat.com/projects/WaveletComp/WaveletComp_guided_tour.pdf), \"[the] average power plot cannot distinguish between consecutive periods and overlapping periods.\" This is a limitation, but using average power is definitely a great first step toward a robust classification of training plan patterns.\n",
    "supporting": [
      "timeseries-clustering-part2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}